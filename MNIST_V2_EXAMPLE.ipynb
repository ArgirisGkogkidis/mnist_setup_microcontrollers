{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlvxv6QyKDKnsY1mWiRF8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArgirisGkogkidis/mnist_setup_microcontrollers/blob/main/MNIST_V2_EXAMPLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7bMV-e6f0JD",
        "outputId": "742ca67d-84e1-4046-f9b8-4e8e53996e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "## TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "## Helper libraries\n",
        "import numpy as np\n",
        "import binascii\n",
        "import logging\n",
        "\n",
        "## Check the version of tensorflow (should be 2.8.0)\n",
        "print(tf.__version__)\n",
        "\n",
        "## To silent verbose\n",
        "tf.autograph.set_verbosity(0)\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MNIST download\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# 60,000 training data and 10,000 test data of 28x28 pixel images\n",
        "print(\"train_images shape\", train_images.shape)\n",
        "print(\"train_labels shape\", train_labels.shape)\n",
        "print(\"test_images shape\", test_images.shape)\n",
        "print(\"test_labels shape\", test_labels.shape)\n",
        "\n",
        "## Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images/255.0;\n",
        "test_images = test_images/255.0;\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "print('Datasets are normalized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw1arqoff_wo",
        "outputId": "c18edbce-a74e-476b-af6b-396d6d78e60e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "train_images shape (60000, 28, 28)\n",
            "train_labels shape (60000,)\n",
            "test_images shape (10000, 28, 28)\n",
            "test_labels shape (10000,)\n",
            "Datasets are normalized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model definition\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=6, kernel_size=(5, 5), \n",
        "    padding='same', activation=tf.nn.relu, name=\"conv2d_6\"), \n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(32, activation=tf.nn.relu, name=\"dense_32\"),\n",
        "  keras.layers.Dense(10),\n",
        "  keras.layers.Activation(tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "## Output the summary of the model\n",
        "model.summary()\n",
        "\n",
        "## Training the model\n",
        "model.fit(x=train_images, y=train_labels, \n",
        "  batch_size=128, epochs=30, verbose=1, validation_split=0.1)\n",
        "\n",
        "## Evaluate the model using all images in the test dataset.\n",
        "test_loss, test_acc = model.evaluate(x=test_images, y=test_labels, verbose=1)\n",
        "print('Accuracy = %f' % test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCN2M2DDgCmZ",
        "outputId": "24617cb3-4ebd-4d93-837a-f2f149b59dbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1176)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 32)                37664     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                330       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,150\n",
            "Trainable params: 38,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "422/422 [==============================] - 23s 52ms/step - loss: 0.4587 - accuracy: 0.8648 - val_loss: 0.1879 - val_accuracy: 0.9470\n",
            "Epoch 2/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.1964 - accuracy: 0.9420 - val_loss: 0.1291 - val_accuracy: 0.9680\n",
            "Epoch 3/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.1417 - accuracy: 0.9581 - val_loss: 0.1036 - val_accuracy: 0.9728\n",
            "Epoch 4/30\n",
            "422/422 [==============================] - 15s 36ms/step - loss: 0.1105 - accuracy: 0.9674 - val_loss: 0.0866 - val_accuracy: 0.9768\n",
            "Epoch 5/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0902 - accuracy: 0.9739 - val_loss: 0.0894 - val_accuracy: 0.9745\n",
            "Epoch 6/30\n",
            "422/422 [==============================] - 19s 46ms/step - loss: 0.0783 - accuracy: 0.9763 - val_loss: 0.0718 - val_accuracy: 0.9795\n",
            "Epoch 7/30\n",
            "422/422 [==============================] - 17s 40ms/step - loss: 0.0683 - accuracy: 0.9792 - val_loss: 0.0650 - val_accuracy: 0.9823\n",
            "Epoch 8/30\n",
            "422/422 [==============================] - 18s 43ms/step - loss: 0.0590 - accuracy: 0.9825 - val_loss: 0.0692 - val_accuracy: 0.9818\n",
            "Epoch 9/30\n",
            "422/422 [==============================] - 18s 42ms/step - loss: 0.0537 - accuracy: 0.9841 - val_loss: 0.0566 - val_accuracy: 0.9847\n",
            "Epoch 10/30\n",
            "422/422 [==============================] - 17s 40ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.0571 - val_accuracy: 0.9845\n",
            "Epoch 11/30\n",
            "422/422 [==============================] - 18s 42ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.0621 - val_accuracy: 0.9833\n",
            "Epoch 12/30\n",
            "422/422 [==============================] - 16s 39ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.0566 - val_accuracy: 0.9842\n",
            "Epoch 13/30\n",
            "422/422 [==============================] - 16s 37ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0580 - val_accuracy: 0.9845\n",
            "Epoch 14/30\n",
            "422/422 [==============================] - 17s 39ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0556 - val_accuracy: 0.9862\n",
            "Epoch 15/30\n",
            "422/422 [==============================] - 15s 37ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.0666 - val_accuracy: 0.9847\n",
            "Epoch 16/30\n",
            "422/422 [==============================] - 17s 39ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0603 - val_accuracy: 0.9855\n",
            "Epoch 17/30\n",
            "422/422 [==============================] - 15s 36ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.0598 - val_accuracy: 0.9852\n",
            "Epoch 18/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0550 - val_accuracy: 0.9868\n",
            "Epoch 19/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0592 - val_accuracy: 0.9857\n",
            "Epoch 20/30\n",
            "422/422 [==============================] - 17s 40ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0616 - val_accuracy: 0.9852\n",
            "Epoch 21/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0570 - val_accuracy: 0.9855\n",
            "Epoch 22/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0628 - val_accuracy: 0.9862\n",
            "Epoch 23/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0627 - val_accuracy: 0.9850\n",
            "Epoch 24/30\n",
            "422/422 [==============================] - 15s 36ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0645 - val_accuracy: 0.9855\n",
            "Epoch 25/30\n",
            "422/422 [==============================] - 15s 36ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0662 - val_accuracy: 0.9865\n",
            "Epoch 26/30\n",
            "422/422 [==============================] - 15s 37ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0659 - val_accuracy: 0.9858\n",
            "Epoch 27/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0680 - val_accuracy: 0.9853\n",
            "Epoch 28/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0641 - val_accuracy: 0.9862\n",
            "Epoch 29/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0648 - val_accuracy: 0.9863\n",
            "Epoch 30/30\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0716 - val_accuracy: 0.9850\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0668 - accuracy: 0.9827\n",
            "Accuracy = 0.982700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert the Keras model to a quantized TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "def representative_dataset_gen():\n",
        "   for i in range(100):\n",
        "      input_image = tf.cast(test_images[i], tf.float32)\n",
        "      input_image = tf.reshape(input_image, [1,28,28])\n",
        "      yield ([input_image])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "## Show the quantized model size in KBs.\n",
        "tflite_model_size = len(tflite_model) / 1024\n",
        "print('Quantized model size = %dKBs.' % tflite_model_size)\n",
        "# Save the model to disk\n",
        "open('qmodel.tflite', \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "HJVJpeKEgFxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --CUSTOM-- ARGIRIS\n",
        "# Previous setp we store qmodel.tflite, its the quantized version of the model made by TF. \n",
        "# One option is to keep that file and convert to C-style header (xxd for example or the following code)\n",
        "# !xxd -i model.tflite > model.h \n",
        "# requires xxd to be installed or a Linux machine"
      ],
      "metadata": {
        "id": "y_r6yt8lgYg4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Output the quantized tflite model to a c-style header\n",
        "'''\n",
        "def convert_to_c_array(bytes) -> str:\n",
        "  hexstr = binascii.hexlify(bytes).decode(\"UTF-8\")\n",
        "  hexstr = hexstr.upper()\n",
        "  array = [\"0x\" + hexstr[i:i + 2] for i in range(0, len(hexstr), 2)]\n",
        "  array = [array[i:i+10] for i in range(0, len(array), 10)]\n",
        "  return \",\\n  \".join([\", \".join(e) for e in array])\n",
        "\n",
        "tflite_binary = open('model.tflite', 'rb').read()\n",
        "ascii_bytes = convert_to_c_array(tflite_binary)\n",
        "header_file = \"const unsigned char model_tflite[] = {\\n  \" + ascii_bytes + \"\\n};\\nunsigned int model_tflite_len = \" + str(len(tflite_binary)) + \";\"\n",
        "with open(\"model.h\", \"w\") as f:\n",
        "    f.write(header_file)\n",
        "'''"
      ],
      "metadata": {
        "id": "NBXFbjwigiKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other option is to use another framework like tinymlgen (!pip install tinymlgen)\n",
        "# and use \n",
        "# from tinymlgen import port\n",
        "# c_code = port(model,variable_name='mnist_model', pretty_print=True)\n",
        "# print(c_code)"
      ],
      "metadata": {
        "id": "bGAMBPrrguuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}